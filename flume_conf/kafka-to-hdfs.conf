# Flume 配置文件: Kafka Source -> HDFS Sink
# 功能: 从 Kafka 消费 nowcoder_jobs 数据并写入 HDFS
# 部署位置: /home/hadoop/soft/apache-flume-1.10.0-bin/conf/kafka-to-hdfs.conf

# ==================== Agent 名称定义 ====================
a1.sources = kafka-source
a1.channels = memory-channel
a1.sinks = hdfs-sink

# ==================== Kafka Source 配置 ====================
a1.sources.kafka-source.type = org.apache.flume.source.kafka.KafkaSource
a1.sources.kafka-source.kafka.bootstrap.servers = 192.168.120.101:9092,192.168.120.102:9092,192.168.120.103:9092
a1.sources.kafka-source.kafka.topics = nowcoder_jobs
a1.sources.kafka-source.kafka.consumer.group.id = flume-hdfs-v3-20251225
a1.sources.kafka-source.batchSize = 500
a1.sources.kafka-source.batchDurationMillis = 2000
a1.sources.kafka-source.kafka.consumer.auto.offset.reset = earliest
a1.sources.kafka-source.setTopicHeader = true
a1.sources.kafka-source.topicHeader = topic

# ==================== Memory Channel 配置 ====================
a1.channels.memory-channel.type = memory
a1.channels.memory-channel.capacity = 10000
a1.channels.memory-channel.transactionCapacity = 1000

# ==================== HDFS Sink 配置 ====================
a1.sinks.hdfs-sink.type = hdfs
a1.sinks.hdfs-sink.hdfs.path = hdfs://mycluster/user/hadoop/nowcoder_jobs/dt=%Y%m%d
a1.sinks.hdfs-sink.hdfs.filePrefix = jobs
a1.sinks.hdfs-sink.hdfs.fileSuffix = .json
a1.sinks.hdfs-sink.hdfs.useLocalTimeStamp = true

# 滚动策略
a1.sinks.hdfs-sink.hdfs.rollInterval = 60
a1.sinks.hdfs-sink.hdfs.rollSize = 134217728
a1.sinks.hdfs-sink.hdfs.rollCount = 0

# 文件格式
a1.sinks.hdfs-sink.hdfs.fileType = DataStream
a1.sinks.hdfs-sink.hdfs.writeFormat = Text

# 批量写入
a1.sinks.hdfs-sink.hdfs.batchSize = 1000

# ==================== 绑定 Source 和 Sink 到 Channel ====================
a1.sources.kafka-source.channels = memory-channel
a1.sinks.hdfs-sink.channel = memory-channel
